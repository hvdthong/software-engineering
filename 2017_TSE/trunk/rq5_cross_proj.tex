% Table generated by Excel2LaTeX from sheet 'cross_project'
\begin{table*}[t!]
  \centering
  \caption{\textbf{Top@N} (\textbf{N} $\in {\{1, 5, 10\}}$ and Mean Average Precision (MAP) results of NetML for cross-project and within-project defect prediction. We use the shorthand names for program for brevity. \textbf{``CP''} stands for cross-project and \textbf{``WP''} stands for within-project. The best results of cross-project are highlighted in bold. }
    \begin{tabular}{|l|l|c|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{1}{|c|}{\multirow{2}[4]{*}{\textbf{Source}}} & \multicolumn{1}{c|}{\multirow{2}[4]{*}{\textbf{Target}}} & \multicolumn{2}{c|}{\textbf{Top 1}} & \multicolumn{2}{c|}{\textbf{Top 5}} & \multicolumn{2}{c|}{\textbf{Top 10}} & \multicolumn{2}{c|}{\textbf{MAP}} \\
\cline{3-10}          &       & \textbf{CP} & \textbf{WP} & \textbf{CP} & \textbf{WP} & \textbf{CP} & \textbf{WP} & \textbf{CP} & \textbf{WP} \\
    \hline
    \hline
    Aspectj & Ant   & 8     & \multirow{6}[2]{*}{13} & 20    & \multirow{6}[2]{*}{24} & 31    & \multirow{6}[2]{*}{35} & 0.181 & \multirow{6}[2]{*}{0.27} \\
    Lang  & Ant   & 7     &       & 21    &       & 30    &       & 0.188 &  \\
    Lucene & Ant   & 7     &       & 23    &       & 31    &       & 0.210  &  \\
    Math  & Ant   & \textbf{8}     &       & \textbf{22}    &       & \textbf{31}    &       & \textbf{0.192} &  \\
    Rhino & Ant   & 7     &       & 21    &       & 30    &       & 0.188 &  \\
    Time  & Ant   & 7     &       & 15    &       & 27    &       & 0.164 &  \\
    \hline
    Ant   & Aspectj & 3     & \multirow{6}[2]{*}{11} & 9     & \multirow{6}[2]{*}{15} & 9     & \multirow{6}[2]{*}{16} & 0.106 & \multirow{6}[2]{*}{0.219} \\
    Lang  & Aspectj & 3     &       & 8     &       & 9     &       & 0.098 &  \\
    Lucene  & Aspectj & 3     &       & 6     &       & 7     &       & 0.089 &  \\
    Math  & Aspectj & 2     &       & 3     &       & 4     &       & 0.052 &  \\
    Rhino & Aspectj & \textbf{4}     &       & \textbf{6}     &       & \textbf{8}     &       & \textbf{0.103} &  \\
    Time  & Aspectj & 2     &       & 3     &       & 5     &       & 0.066 &  \\
    \hline
    Ant   & Lang  & 17    & \multirow{6}[2]{*}{30} & 31    & \multirow{6}[2]{*}{62} & 39    & \multirow{6}[2]{*}{62} & 0.335 & \multirow{6}[2]{*}{0.638} \\
    Aspectj & Lang  & 16    &       & 31    &       & 37    &       & 0.324 &  \\
    Lucene & Lang  & \textbf{17}    &       & \textbf{33}    &       & \textbf{40}    &       & \textbf{0.349} &  \\
    Math  & Lang  & 17    &       & 31    &       & 39    &       & 0.330  &  \\
    Rhino & Lang  & 17    &       & 31    &       & 38    &       & 0.330  &  \\
    Time  & Lang  & 12    &       & 29    &       & 35    &       & 0.276 &  \\
    \hline
    Aspectj   & Lucene & 3     & \multirow{6}[2]{*}{12} & 15    & \multirow{6}[2]{*}{25} & 20    & \multirow{6}[2]{*}{30} & 0.136 & \multirow{6}[2]{*}{0.29} \\
    Ant   & Lucene & 3     & & 14    & & 20 && 0.150 &\\
    Lang  & Lucene & \textbf{3}     &       & \textbf{16}    &       & \textbf{21}    &       & \textbf{0.150}  &  \\
    Math  & Lucene & 3     &       & 16    &       & 21    &       & 0.150  &  \\
    Rhino & Lucene & 3     &       & 15    &       & 21    &       & 0.149 &  \\
    Time  & Lucene & 2     &       & 12    &       & 16    &       & 0.131 &  \\
    \hline
    Ant   & Math  & \textbf{14}    & \multirow{6}[2]{*}{32} & \textbf{39}    &\multirow{6}[2]{*}{69}& \textbf{49}    & \multirow{6}[2]{*}{75}& \textbf{0.236} &\multirow{6}[2]{*}{0.358}  \\
    Aspectj   & Math  & 12    &  & 35    &  & 49    &  & 0.221 &  \\
    Lang  & Math  & 14    &       & 37    &       & 48    &       & 0.227 &  \\
    Lucene & Math  & 14    &       & 38    &       & 49    &       & 0.236 &  \\
    Rhino & Math  & 14    &       & 38    &       & 49    &       & 0.232 &  \\
    Time  & Math  & 11    &       & 35    &       & 49    &       & 0.208 &  \\
    \hline
    Ant   & Rhino & 2     & \multirow{6}[2]{*}{10} & 11    & \multirow{6}[2]{*}{18} & 14    & \multirow{6}[2]{*}{19} & 0.188 & \multirow{6}[2]{*}{0.302} \\
    Aspectj & Rhino & \textbf{3}     &       & \textbf{10}    &       & \textbf{14}    &       & \textbf{0.205} &  \\
    Lang  & Rhino & 2     &       & 8     &       & 13    &       & 0.177 &  \\
    Lucene & Rhino & 2     &       & 11    &       & 15    &       & 0.187 &  \\
    Math  & Rhino & 3     &       & 10    &       & 14    &       & 0.196 &  \\
    Time  & Rhino & 3     &       & 9     &       & 12    &       & 0.171 &  \\
    \hline
    Ant   & Time  & 1     & \multirow{6}[2]{*}{8} & 4     & \multirow{6}[2]{*}{13} & 5     & \multirow{6}[2]{*}{18} & 0.109  & \multirow{6}[2]{*}{0.354} \\
    Aspectj & Time  & 0     &       & 3     &       & 3     &       & 0.153 &  \\
    Lang  & Time  & 1     &       & 4     &       & 5     &       & 0.109  &  \\
    Lucene & Time  & \textbf{1}     &       & \textbf{4}     &       & \textbf{ 5 }    &       &\textbf{0.189} &  \\
    Math  & Time  & 1     &       & 4     &       & 5     &       & 0.109  &  \\
    Rhino & Time  & 1     &       & 5     &       & 6     &       & 0.191 &  \\
    \hline
    \end{tabular}%
  \label{tab:cross_proj}%
\end{table*}%

\begin{table}[t!]
	\centering
	\caption{Comparison of the best results in NetML cross-project vs. NetML within-project. The $p$-values of the Wilcoxon test apply on both NetML models (i.e., cross project and within project). We use the shorthand names for program for brevity. \textbf{``CP''} stands for cross-project and \textbf{``WP''} stands for within-project.}
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Metrics} & \textbf{CP} & \textbf{WP} & \textbf{$p$\_values} \\
		\hline
		\hline
		\textbf{Top 1} & 50    & 116     & $ 2 \times 10^{-11}$ (**) \\
		\textbf{Top 5} & 130   & 226   & $ 3 \times 10^{-8}$ (**)\\
		\textbf{Top 10} & 168   & 255   & $ 4 \times 10^{-5}$ (**)\\
		\textbf{MAP} & 0.189 & 0.347 & $ 7 \times 10^{-15}$ (**) \\
		\hline
		\multicolumn{4}{l}{(*): smaller than $0.05$, (**): smaller than $0.01$}
	\end{tabular}%
	\label{tab:best_cross_proj}%
\end{table}%

Table~\ref{tab:cross_proj} presents the performance of NetML in cross-project and within-project defect prediction, in term of the Top N and MAP score. The best results of Top N and MAP score are in bold. We take an example of the experiment where the source project (training data) is from Lucene, and the target project (test set) is from Lang. Running NetML with Lucene as the training set and Lang as the test set detects 17, 33, and 40 bugs in term of the top 1, 5, and 10 methods respectively. The within-project defection for this experiments finds 30, 62, and 62 bugs when a developer inspects the top 1, 5, and 10 methods. It shows that the NetML within-project surpasses NetML cross-project by 176.47\%, 187.88\% and 155\% in the top 1, top 5 and 10 methods. In term of MAP, NetML within-project outperforms the NetML cross-project 182.81\%. 

Table~\ref{tab:best_cross_proj} shows the comparison of NetML in cross-project and within project defect prediction. For each target project, we select the best results in term of the top 1, top 5, top 10 and MAP score. We apply the Wilcoxon test to assess whether NetML cross-project and NetML within-project are statistically significant. NetML within-project outperforms the NetML cross-project in term of Top 1, Top 5, Top 10 and MAP scores. Table~\ref{tab:best_cross_proj} also shows that NetML within-project is significantly better than NetML cross-project in various evaluation metrics (i.e., Top 1, Top 5, Top 10, and MAP). We believe that bugs and methods between two projects are entirely independent since each project has its purpose. For example, Lang provides a host of helper utilities for the \textit{java.lang} whereas Ant mainly uses to build of Java applications. Hence, NetML is unable to capture the latent parameters of bug reports and methods across projects, leading to achieving paltry results in NetML cross-project compared to NetML within-project.

  

